{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cardiovascular_Disease.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "64x8zUnXALhK",
        "butICZDAZSgG",
        "TCmgjlWFZgks",
        "Xi78HjLWZl4h",
        "HXgWfYaMXWGY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Necessary Libraries**"
      ],
      "metadata": {
        "id": "64x8zUnXALhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# NumPy\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "# Sci-Kit Learn\n",
        "import sklearn\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Tensorflow / Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks, Sequential\n",
        "from keras.layers import Dropout, BatchNormalization, Activation, Dense\n",
        "\n",
        "# Math Libraries\n",
        "import random\n",
        "from random import uniform\n",
        "import math\n",
        "import scipy\n",
        "from scipy.stats import norm, t, chi2\n",
        "\n",
        "# Pickle\n",
        "import pickle\n",
        "\n",
        "# LIME\n",
        "!pip install lime\n",
        "import lime\n",
        "from lime import lime_tabular\n",
        "\n",
        "# Print Confirmation\n",
        "print(\"Setup Complete\")"
      ],
      "metadata": {
        "id": "eJQ6JAHCPW-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Data, Imputation, and Interpolation**"
      ],
      "metadata": {
        "id": "butICZDAZSgG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA_ybcbkPRsr"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/csun365/Cardiovascular-Disease/main/cardiovascular_raw.csv\"\n",
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum().sum()"
      ],
      "metadata": {
        "id": "ggzdJn-jPdLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "3WxELIELW0cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Cholesterol\"] = df[\"Cholesterol\"].replace([0], np.nan)"
      ],
      "metadata": {
        "id": "_6Mg-LSHfEwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"RestingBP\"] = df[\"RestingBP\"].replace([0], np.median(df[\"RestingBP\"]))"
      ],
      "metadata": {
        "id": "4fuY0siqBw6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Sex\"] = df[\"Sex\"] == \"M\"\n",
        "df[\"ExerciseAngina\"] = df[\"ExerciseAngina\"] == \"Y\"\n",
        "df = pd.get_dummies(df, columns=[\"ChestPainType\", \"RestingECG\", \"ST_Slope\"])"
      ],
      "metadata": {
        "id": "lJHfpO0ptnnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = df.columns.tolist()\n",
        "idx = cols.index(\"HeartDisease\")\n",
        "cols = cols[:idx] + cols[idx+1:] + [\"HeartDisease\"]\n",
        "df = df[cols]"
      ],
      "metadata": {
        "id": "F6U2YQpw-qYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_impute = []\n",
        "Y_impute = []\n",
        "for i in range(df.shape[0]):\n",
        "  if df[\"Cholesterol\"].isna()[i] == 0:\n",
        "    X_impute.append(df.iloc[i,:-1])\n",
        "    Y_impute.append(df.iloc[i,-1])\n",
        "X_impute = np.array(X_impute)\n",
        "Y_impute = np.array(Y_impute)"
      ],
      "metadata": {
        "id": "V4aAn_OtskVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t_impute, X_v_impute, y_t_impute, y_v_impute = train_test_split(X_impute, Y_impute, test_size=0.25, random_state=1)"
      ],
      "metadata": {
        "id": "mvXjiMpfpvT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "choices = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,30,40,50,100,200]\n",
        "best_k = 1\n",
        "best_accuracy = 0\n",
        "for i in choices:\n",
        "  KNC = KNeighborsClassifier(n_neighbors = i).fit(X_t_impute, y_t_impute)\n",
        "  y_pred_impute = KNC.predict(X_v_impute)\n",
        "  accuracy = accuracy_score(y_v_impute, y_pred_impute)\n",
        "  if accuracy > best_accuracy:\n",
        "    best_accuracy = accuracy\n",
        "    best_k = i\n",
        "  print(\"K = \" + str(i) + \" : \" + str(accuracy))\n",
        "print(\"Best K: \" + str(best_k))"
      ],
      "metadata": {
        "id": "AMZTlCgHobx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = KNNImputer(n_neighbors=best_k)\n",
        "imputed = imputer.fit_transform(df)\n",
        "df[\"Cholesterol\"] = imputed[:,3]"
      ],
      "metadata": {
        "id": "gTD5LQ9bhuI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"cardiovascular_imputed_interpolated.csv\", index=False)"
      ],
      "metadata": {
        "id": "mH9agk6UzE1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/csun365/Cardiovascular-Disease/main/cardiovascular_imputed_interpolated.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "xrYt3qnNzizY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,:-1].values.astype(float)\n",
        "Y = df.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "-EvRptaIZHYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t, X_v, y_t, y_v = train_test_split(X, Y, test_size=0.25, random_state=2)\n",
        "\n",
        "print(\"Number of patients in train set: \" + str(y_t.shape[0]))\n",
        "print(\"Number of patients in validation set: \" + str(y_v.shape[0]))"
      ],
      "metadata": {
        "id": "M_o4x0MQab7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "TCmgjlWFZgks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_neg = df[df[\"HeartDisease\"] == 0]\n",
        "df_pos = df[df[\"HeartDisease\"] == 1]"
      ],
      "metadata": {
        "id": "4wABHAgdc6Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t_mean = np.mean(X_t, axis=0)\n",
        "X_t_std = np.std(X_t, axis=0)\n",
        "\n",
        "X_t = (X_t - X_t_mean) / X_t_std\n",
        "X_v = (X_v - X_t_mean) / X_t_std"
      ],
      "metadata": {
        "id": "ogLkT47Wrq3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [0,2,3,5,7]\n",
        "for i in cols:\n",
        "  print(\"Minimum \" + str(df.columns[i]) + \": \" + str(df.iloc[:,i].min()))\n",
        "  print(\"Maximum \" + str(df.columns[i]) + \": \" + str(df.iloc[:,i].max()))\n",
        "  print()"
      ],
      "metadata": {
        "id": "J062iUcfGBjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def degrees_of_freedom(sigma1, n1, sigma2, n2):\n",
        "  numerator = (sigma1 ** 2 / n1 + sigma2 ** 2 / n2) ** 2\n",
        "  denominator = (sigma1 ** 2 / n1) ** 2 / (n1 - 1) + (sigma2 ** 2 / n2) ** 2 / (n2 - 1)\n",
        "  return numerator / denominator"
      ],
      "metadata": {
        "id": "RwXer9FMNPAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Two Sample \n",
        "pos_mean_age = np.mean(df_pos[\"Age\"])\n",
        "neg_mean_age = np.mean(df_neg[\"Age\"])\n",
        "pos_std_age = np.std(df_pos[\"Age\"])\n",
        "neg_std_age = np.std(df_neg[\"Age\"])\n",
        "\n",
        "t_age = (pos_mean_age - neg_mean_age) / (pos_std_age ** 2 / df_pos.shape[0] + neg_std_age ** 2 / df_neg.shape[0]) ** 0.5\n",
        "print(t_age)\n",
        "df_age = degrees_of_freedom(pos_std_age, df_pos.shape[0], neg_std_age, df_neg.shape[0])\n",
        "print(df_age)\n",
        "p_age = t.cdf(-t_age, df=df_age)\n",
        "print(p_age)"
      ],
      "metadata": {
        "id": "rQfI0A1Boi9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_mean_BP = np.mean(df_pos[\"RestingBP\"])\n",
        "neg_mean_BP = np.mean(df_neg[\"RestingBP\"])\n",
        "pos_std_BP = np.std(df_pos[\"RestingBP\"])\n",
        "neg_std_BP = np.std(df_neg[\"RestingBP\"])\n",
        "\n",
        "t_BP = (pos_mean_BP - neg_mean_BP) / (pos_std_BP ** 2 / df_pos.shape[0] + neg_std_BP ** 2 / df_neg.shape[0]) ** 0.5\n",
        "print(t_BP)\n",
        "df_BP = degrees_of_freedom(pos_std_BP, df_pos.shape[0], neg_std_BP, df_neg.shape[0])\n",
        "print(df_BP)\n",
        "p_BP = t.cdf(-t_BP, df=df_BP)\n",
        "print(p_BP)"
      ],
      "metadata": {
        "id": "M-G0fHzTdAm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_mean_chol = np.mean(df_pos[\"Cholesterol\"])\n",
        "neg_mean_chol = np.mean(df_neg[\"Cholesterol\"])\n",
        "pos_std_chol = np.std(df_pos[\"Cholesterol\"])\n",
        "neg_std_chol = np.std(df_neg[\"Cholesterol\"])\n",
        "\n",
        "t_chol = (pos_mean_chol - neg_mean_chol) / (pos_std_chol ** 2 / df_pos.shape[0] + neg_std_chol ** 2 / df_neg.shape[0]) ** 0.5\n",
        "print(t_chol)\n",
        "df_chol = degrees_of_freedom(pos_std_chol, df_pos.shape[0], neg_std_chol, df_neg.shape[0])\n",
        "print(df_chol)\n",
        "p_chol = t.cdf(-t_chol, df=df_chol)\n",
        "print(p_chol)"
      ],
      "metadata": {
        "id": "wOEirnVRkupx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_mean_HR = np.mean(df_pos[\"MaxHR\"])\n",
        "neg_mean_HR = np.mean(df_neg[\"MaxHR\"])\n",
        "pos_std_HR = np.std(df_pos[\"MaxHR\"])\n",
        "neg_std_HR = np.std(df_neg[\"MaxHR\"])\n",
        "\n",
        "t_HR = (pos_mean_HR - neg_mean_HR) / (pos_std_HR ** 2 / df_pos.shape[0] + neg_std_HR ** 2 / df_neg.shape[0]) ** 0.5\n",
        "print(t_HR)\n",
        "df_HR = degrees_of_freedom(pos_std_HR, df_pos.shape[0], neg_std_HR, df_neg.shape[0])\n",
        "print(df_HR)\n",
        "p_HR = t.cdf(t_HR, df=df_HR)\n",
        "print(p_HR)"
      ],
      "metadata": {
        "id": "RVskMJV3ruk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_mean_oldpeak = np.mean(df_pos[\"Oldpeak\"])\n",
        "neg_mean_oldpeak = np.mean(df_neg[\"Oldpeak\"])\n",
        "pos_std_oldpeak = np.std(df_pos[\"Oldpeak\"])\n",
        "neg_std_oldpeak = np.std(df_neg[\"Oldpeak\"])\n",
        "\n",
        "t_oldpeak = (pos_mean_oldpeak - neg_mean_oldpeak) / (pos_std_oldpeak ** 2 / df_pos.shape[0] + neg_std_oldpeak ** 2 / df_neg.shape[0]) ** 0.5\n",
        "print(t_oldpeak)\n",
        "df_oldpeak = degrees_of_freedom(pos_std_oldpeak, df_pos.shape[0], neg_std_oldpeak, df_neg.shape[0])\n",
        "print(df_oldpeak)\n",
        "p_oldpeak = t.cdf(-t_oldpeak, df=df_oldpeak)\n",
        "print(p_oldpeak)"
      ],
      "metadata": {
        "id": "Ak_goVlfk9et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [0,2,3,5,7]\n",
        "fig, ax = plt.subplots(2, 3, figsize=(15,6))\n",
        "coords = [(i,j) for i in range(2) for j in range(3)]\n",
        "counter = 0\n",
        "for i in cols:\n",
        "  ax[coords[counter]].set_title(df.columns[i])\n",
        "  ax[coords[counter]].hist(df_pos[df.columns[i]], label=\"Positive\", alpha = 0.7, color=\"r\", bins=10)\n",
        "  ax[coords[counter]].hist(df_neg[df.columns[i]], label=\"Negative\", alpha = 0.7, color=\"b\", bins=10)\n",
        "  ax[coords[counter]].legend()\n",
        "  counter += 1\n",
        "ax[1,2].remove()\n",
        "plt.savefig(\"EDA_means.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uux2IHPik9e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chi-Square \n",
        "obs_chest_pain = np.array([[df_pos[df_pos[\"ChestPainType_ATA\"] == 1].shape[0], df_neg[df_neg[\"ChestPainType_ATA\"] == 1].shape[0]],\n",
        "                           [df_pos[df_pos[\"ChestPainType_NAP\"] == 1].shape[0], df_neg[df_neg[\"ChestPainType_NAP\"] == 1].shape[0]],\n",
        "                           [df_pos[df_pos[\"ChestPainType_ASY\"] == 1].shape[0], df_neg[df_neg[\"ChestPainType_ASY\"] == 1].shape[0]],\n",
        "                           [df_pos[df_pos[\"ChestPainType_TA\"] == 1].shape[0], df_neg[df_neg[\"ChestPainType_TA\"] == 1].shape[0]]])\n",
        "\n",
        "exp_chest_pain = np.zeros((obs_chest_pain.shape[0], obs_chest_pain.shape[1]))\n",
        "for i in range(exp_chest_pain.shape[0]):\n",
        "  for j in range(exp_chest_pain.shape[1]):\n",
        "    exp_chest_pain[i][j] = np.sum(obs_chest_pain, axis=0)[j] * np.sum(obs_chest_pain, axis=1)[i] / np.sum(obs_chest_pain)\n",
        "\n",
        "X2_chest_pain = np.sum(np.divide(np.square(obs_chest_pain - exp_chest_pain), exp_chest_pain))\n",
        "print(X2_chest_pain)\n",
        "p_chest_pain = chi2.cdf(-X2_chest_pain, df=3)\n",
        "print(p_chest_pain)"
      ],
      "metadata": {
        "id": "78pZaTAa000-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs_ECG = np.array([[df_pos[df_pos[\"RestingECG_Normal\"] == 1].shape[0], df_neg[df_neg[\"RestingECG_Normal\"] == 1].shape[0]],\n",
        "                           [df_pos[df_pos[\"RestingECG_ST\"] == 1].shape[0], df_neg[df_neg[\"RestingECG_ST\"] == 1].shape[0]],\n",
        "                           [df_pos[df_pos[\"RestingECG_LVH\"] == 1].shape[0], df_neg[df_neg[\"RestingECG_LVH\"] == 1].shape[0]]])\n",
        "\n",
        "exp_ECG = np.zeros((obs_ECG.shape[0], obs_ECG.shape[1]))\n",
        "for i in range(exp_ECG.shape[0]):\n",
        "  for j in range(exp_ECG.shape[1]):\n",
        "    exp_ECG[i][j] = np.sum(obs_ECG, axis=0)[j] * np.sum(obs_ECG, axis=1)[i] / np.sum(obs_ECG)\n",
        "\n",
        "X2_ECG = np.sum(np.divide(np.square(obs_ECG - exp_ECG), exp_ECG))\n",
        "print(X2_ECG)\n",
        "p_ECG = chi2.cdf(-X2_ECG, df=2)\n",
        "print(p_ECG)"
      ],
      "metadata": {
        "id": "IVbWsLYh4p1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs_ST = np.array([[df_pos[df_pos[\"ST_Slope_Up\"] == 1].shape[0], df_neg[df_neg[\"ST_Slope_Up\"] == 1].shape[0]],\n",
        "                           [df_pos[df_pos[\"ST_Slope_Flat\"] == 1].shape[0], df_neg[df_neg[\"ST_Slope_Flat\"] == 1].shape[0]],\n",
        "                           [df_pos[df_pos[\"ST_Slope_Down\"] == 1].shape[0], df_neg[df_neg[\"ST_Slope_Down\"] == 1].shape[0]]])\n",
        "\n",
        "exp_ST = np.zeros(obs_ST.shape)\n",
        "for i in range(exp_ST.shape[0]):\n",
        "  for j in range(exp_ST.shape[1]):\n",
        "    exp_ST[i][j] = np.sum(obs_ST, axis=0)[j] * np.sum(obs_ST, axis=1)[i] / np.sum(obs_ST)\n",
        "\n",
        "X2_ST = np.sum(np.divide(np.square(obs_ST - exp_ST), exp_ST))\n",
        "print(X2_ST)\n",
        "p_ST = chi2.cdf(-X2_ST, df=2)\n",
        "print(p_ST)"
      ],
      "metadata": {
        "id": "NCJ5iN5AOAjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Two Propotion\n",
        "pos_M = df[(df[\"HeartDisease\"] == 1) & (df[\"Sex\"] == 1)].shape[0]\n",
        "pos_F = df[(df[\"HeartDisease\"] == 1) & (df[\"Sex\"] == 0)].shape[0]\n",
        "tot_M = df[df[\"Sex\"] == 1].shape[0]\n",
        "tot_F = df[df[\"Sex\"] == 0].shape[0]\n",
        "prop_M = pos_M / tot_M\n",
        "prop_F = pos_F / tot_F\n",
        "prop_pool_sex = (pos_M + pos_F) / (tot_M + tot_F)\n",
        "\n",
        "z_sex = (prop_M - prop_F) / ((prop_pool_sex * (1 - prop_pool_sex) * (1 / tot_M + 1 / tot_F)) ** 0.5)\n",
        "print(z_sex)\n",
        "p_sex = norm.cdf(-z_sex)\n",
        "print(p_sex)"
      ],
      "metadata": {
        "id": "xyrI0ARvPtQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_BShigh = df[(df[\"HeartDisease\"] == 1) & (df[\"FastingBS\"] == 1)].shape[0]\n",
        "pos_BSlow = df[(df[\"HeartDisease\"] == 1) & (df[\"FastingBS\"] == 0)].shape[0]\n",
        "tot_BShigh = df[df[\"FastingBS\"] == 1].shape[0]\n",
        "tot_BSlow = df[df[\"FastingBS\"] == 0].shape[0]\n",
        "prop_BShigh = pos_BShigh / tot_BShigh\n",
        "prop_BSlow = pos_BSlow / tot_BSlow\n",
        "prop_pool_BS = (pos_M + pos_F) / (tot_M + tot_F)\n",
        "\n",
        "z_BS = (prop_BShigh - prop_BSlow) / ((prop_pool_BS * (1 - prop_pool_BS) * (1 / tot_BShigh + 1 / tot_BSlow)) ** 0.5)\n",
        "print(z_BS)\n",
        "p_BS = norm.cdf(-z_BS)\n",
        "print(p_BS)"
      ],
      "metadata": {
        "id": "gACQ6ArGVOl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_angina = df[(df[\"HeartDisease\"] == 1) & (df[\"ExerciseAngina\"] == 1)].shape[0]\n",
        "pos_none = df[(df[\"HeartDisease\"] == 1) & (df[\"ExerciseAngina\"] == 0)].shape[0]\n",
        "tot_angina = df[df[\"ExerciseAngina\"] == 1].shape[0]\n",
        "tot_none = df[df[\"ExerciseAngina\"] == 0].shape[0]\n",
        "prop_angina= pos_angina / tot_angina\n",
        "prop_none = pos_none / tot_none\n",
        "prop_pool_angina = (pos_angina + pos_none) / (tot_angina + tot_none)\n",
        "\n",
        "z_angina = (prop_angina - prop_none) / ((prop_pool_angina * (1 - prop_pool_angina) * (1 / tot_angina + 1 / tot_none)) ** 0.5)\n",
        "print(z_angina)\n",
        "p_angina = norm.cdf(-z_angina)\n",
        "print(p_angina)"
      ],
      "metadata": {
        "id": "mB0JcpS-VnZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predictive Modeling**"
      ],
      "metadata": {
        "id": "Xi78HjLWZl4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_pd(y_pred, y_true):\n",
        "  tp = np.sum(np.logical_and((y_pred==1), (y_true==1)))\n",
        "  fp = np.sum(np.logical_and((y_pred==1), (y_true==0)))\n",
        "  tn = np.sum(np.logical_and((y_pred==0), (y_true==0)))\n",
        "  fn = np.sum(np.logical_and((y_pred==0), (y_true==1)))\n",
        "  \n",
        "  r = tp/(tp + fn) \n",
        "  p = tp/(tp + fp) \n",
        "  \n",
        "  f1 = 2 * p * r / (p + r) \n",
        "  return f1"
      ],
      "metadata": {
        "id": "WdzhDiI8NMrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Model (LR)\n",
        "model_lr = LogisticRegression(random_state=0)\n",
        "model_lr.fit(X_t, y_t)\n",
        "probs_lr = model_lr.predict_proba(X_v)\n",
        "predictions_lr = probs_lr[:,1] >= probs_lr[:,0]\n",
        "binary_accuracy_lr = accuracy_score(y_v, predictions_lr)\n",
        "f1_lr = f1_pd(predictions_lr, y_v)\n",
        "print(\"Logistic Regression Binary Accuracy: \" + str(binary_accuracy_lr))\n",
        "print(\"Logistic Regression F1 Score: \" + str(f1_lr))\n",
        "\n",
        "fpr, tpr, _ = sklearn.metrics.roc_curve(y_v, probs_lr[:,1])\n",
        "plt.plot(fpr,tpr,label=\"AUC = \" + str(sklearn.metrics.roc_auc_score(y_v, probs_lr[:,1])))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cz4ecKAmFhiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Model (RF)\n",
        "model_rf = RandomForestClassifier(n_estimators=100,random_state=0)\n",
        "model_rf.fit(X_t, y_t)\n",
        "probs_rf = model_rf.predict_proba(X_v)\n",
        "predictions_rf = probs_rf[:,1] >= probs_rf[:,0]\n",
        "binary_accuracy_rf = accuracy_score(y_v, predictions_rf)\n",
        "f1_rf = f1_pd(predictions_rf,y_v)\n",
        "print(\"RandomForestClassifier Binary Accuracy: \" + str(binary_accuracy_rf))\n",
        "print(\"RandomForestClassifier F1 Score: \" + str(f1_rf))\n",
        "\n",
        "fpr, tpr, _ = sklearn.metrics.roc_curve(y_v, probs_rf[:,1])\n",
        "plt.plot(fpr,tpr,label=\"AUC = \" + str(sklearn.metrics.roc_auc_score(y_v, probs_rf[:,1])))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "URJ9gTsDMSgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extreme Gradient Boosting Model (XGB)\n",
        "model_xgb = XGBClassifier(n_estimators=100,learning_rate=1e-1,n_jobs=4,random_state=0)\n",
        "model_xgb.fit(X_t,y_t,early_stopping_rounds=100,eval_set=[(X_v,y_v)],verbose=False)\n",
        "probs_xgb = model_xgb.predict_proba(X_v)\n",
        "predictions_xgb = probs_xgb[:,1] >= probs_xgb[:,0]\n",
        "binary_accuracy_xgb = accuracy_score(y_v, predictions_xgb)\n",
        "f1_xgb = f1_pd(predictions_xgb, y_v)\n",
        "print(\"XGBClassifier Binary Accuracy: \" + str(binary_accuracy_xgb))\n",
        "print(\"XGBClassifier F1 Score: \" + str(f1_xgb))\n",
        "\n",
        "fpr, tpr, _ = sklearn.metrics.roc_curve(y_v, probs_xgb[:,1])\n",
        "plt.plot(fpr,tpr,label=\"AUC = \" + str(sklearn.metrics.roc_auc_score(y_v, probs_xgb[:,1])))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cq5lBL_HMVJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine (SVM)\n",
        "model_svm = SVC(C=1, kernel=\"rbf\", random_state=0, probability=True)\n",
        "model_svm.fit(X_t,y_t)\n",
        "probs_svm = model_svm.predict_proba(X_v)\n",
        "predictions_svm = probs_svm[:,1] >= probs_svm[:,0]\n",
        "binary_accuracy_svm = accuracy_score(y_v, predictions_svm)\n",
        "f1_svm = f1_pd(predictions_svm,y_v)\n",
        "print(\"Support Vector Machine Binary Accuracy: \" + str(binary_accuracy_svm))\n",
        "print(\"Support Vector Machine F1 Score: \" + str(f1_svm))\n",
        "\n",
        "fpr, tpr, _ = sklearn.metrics.roc_curve(y_v, probs_svm[:,1])\n",
        "plt.plot(fpr,tpr,label=\"AUC = \" + str(sklearn.metrics.roc_auc_score(y_v, probs_svm[:,1])))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JvfcIvZMMWi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_units = 64\n",
        "dropout_rate = 0.4\n",
        "\n",
        "layers_dimensions = [hidden_units,hidden_units,hidden_units,hidden_units]\n",
        "initializer = tf.keras.initializers.GlorotNormal(seed=2) \n",
        "model_nn = keras.Sequential([\n",
        "                            layers.BatchNormalization(input_shape=[X_t.shape[1]]),\n",
        "                            layers.Dense(layers_dimensions[0],kernel_initializer=initializer,bias_initializer='zeros'), \n",
        "                            layers.BatchNormalization(),\n",
        "                            layers.Activation(\"relu\"),\n",
        "                            layers.Dropout(rate=dropout_rate),\n",
        "                            layers.Dense(layers_dimensions[1],kernel_initializer=initializer,bias_initializer='zeros'),\n",
        "                            layers.BatchNormalization(),\n",
        "                            layers.Activation(\"relu\"),\n",
        "                            layers.Dropout(rate=dropout_rate),\n",
        "                            layers.Dense(layers_dimensions[2],kernel_initializer=initializer,bias_initializer='zeros'),\n",
        "                            layers.BatchNormalization(),\n",
        "                            layers.Activation(\"relu\"),\n",
        "                            layers.Dropout(rate=dropout_rate),\n",
        "                            layers.Dense(layers_dimensions[3],kernel_initializer=initializer,bias_initializer='zeros'),\n",
        "                            layers.BatchNormalization(),\n",
        "                            layers.Activation(\"relu\"),\n",
        "                            layers.Dense(1,kernel_initializer=initializer,bias_initializer='zeros'),\n",
        "                            layers.Activation(\"sigmoid\")\n",
        "])\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=5e-3)\n",
        "model_nn.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"binary_accuracy\"])"
      ],
      "metadata": {
        "id": "aLip-UzfbDFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nn.summary()"
      ],
      "metadata": {
        "id": "OlVYc-jodObo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = callbacks.EarlyStopping(monitor=\"val_binary_accuracy\", mode=\"max\", min_delta=0.001, patience=50, restore_best_weights=True)\n",
        "history_nn = model_nn.fit(X_t,y_t,validation_data=(X_v,y_v),callbacks=[early_stopping],batch_size=64,epochs=250,use_multiprocessing=True,verbose=1)\n",
        "history_nn_pd = pd.DataFrame(history_nn.history)"
      ],
      "metadata": {
        "id": "eHukOmIKbEP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history_nn_pd[\"loss\"])\n",
        "plt.plot(history_nn_pd[\"val_loss\"])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_nn_pd[\"binary_accuracy\"])\n",
        "plt.plot(history_nn_pd[\"val_binary_accuracy\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3dvzX7l4dgev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nn.load_weights(\"/content/cardiovascular_model_weights_64_0.4_fourlayers.h5\")"
      ],
      "metadata": {
        "id": "yVbL05wkxjlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model_nn.predict(X_v)\n",
        "y_pred = y_pred.reshape(-1)"
      ],
      "metadata": {
        "id": "8uRu2lMictR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, _ = sklearn.metrics.roc_curve(y_v, y_pred)\n",
        "plt.plot(fpr,tpr,label=\"AUC = \" + str(sklearn.metrics.roc_auc_score(y_v, y_pred)))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NjWINFxnImV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred >= 0.5\n",
        "print(np.sum(y_pred==y_v)/y_pred.shape[0])\n",
        "f1_nn = f1_pd(y_pred, y_v)\n",
        "print(f1_nn)"
      ],
      "metadata": {
        "id": "u3TBj8yMXitJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion(y_pred, y_true):\n",
        "  tp = np.sum(np.logical_and((y_pred==1), (y_true==1)))\n",
        "  fp = np.sum(np.logical_and((y_pred==1), (y_true==0)))\n",
        "  tn = np.sum(np.logical_and((y_pred==0), (y_true==0)))\n",
        "  fn = np.sum(np.logical_and((y_pred==0), (y_true==1)))\n",
        "  return tp, fp, tn, fn"
      ],
      "metadata": {
        "id": "rnlCCheiGqTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion(y_pred, y_v)"
      ],
      "metadata": {
        "id": "aIFUZpRrG7uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_nn_pd.to_csv(\"cardio_model_history.csv\", index=False)\n",
        "model_nn.save_weights(\"cardiovascular_model_weights_64_0.4_fourlayers.h5\")"
      ],
      "metadata": {
        "id": "AWlXrjBIHUys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "gEVQI-hlN6R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient = np.array([40,0,110,100,1,175,0,2,0,0,0,1,0,1,0,0,0,1])\n",
        "patient = (patient - X_t_mean) / X_t_std\n",
        "diagnosis = model_nn.predict(patient.reshape(1,-1))\n",
        "print(diagnosis)"
      ],
      "metadata": {
        "id": "dc8byDLoN4d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-Means Clustering and Local Interpretable Model-Agnostic Explanations (LIME)**"
      ],
      "metadata": {
        "id": "HXgWfYaMXWGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# L2 Normalization for Clustering \n",
        "X_div = np.sum(X**2, axis=0)**0.5\n",
        "X_norm = X/X_div\n",
        "\n",
        "X_pos_clustering = X_norm[Y==1] # The X values of all of the \"Unhealthy patients\""
      ],
      "metadata": {
        "id": "F9LLpSb7RRRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Z score normalization, since this feeds into the model\n",
        "X_pos_lime = X[Y==1] # The X values of all of the \"Unhealthy patients\"\n",
        "X_pos_lime = (X_pos_lime - X_t_mean) / X_t_std"
      ],
      "metadata": {
        "id": "BWzChCkXOhUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQPadIT5V6Dd"
      },
      "source": [
        "# 1. Define cost function\n",
        "def K_means_cost(centroids,X_vals,print_freq=False):\n",
        "  sum = 0\n",
        "  freq = np.zeros((centroids.shape[0],1))\n",
        "  for i in range(X_vals.shape[0]):\n",
        "    dist = np.sum((centroids-X_vals[i,:])**2,axis=1,keepdims=True)**.5\n",
        "    sum+=min(dist)\n",
        "    freq+=(dist==min(dist))\n",
        "  if(print_freq):\n",
        "    print(freq)\n",
        "  return (sum/X_vals.shape[0])[0], freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ln3Rvmk6nwy"
      },
      "source": [
        "# 2. Define cluster candidates\n",
        "cluster_choices = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,25,30,40,50]\n",
        "costs = []\n",
        "for i in cluster_choices:\n",
        "  k_means_testing = KMeans(n_clusters=i, random_state=0)\n",
        "  k_means_testing.fit(X_pos_clustering)\n",
        "  centroids_testing = k_means_testing.cluster_centers_\n",
        "  # 3. Find the cost of each model\n",
        "  cost, freq = K_means_cost(centroids_testing,X_pos_clustering)\n",
        "  costs.append(cost)\n",
        "\n",
        "# 4. Plot it!\n",
        "plt.scatter(cluster_choices,costs)\n",
        "plt.plot(cluster_choices,costs)\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.title(\"Elbow at K = 10\")\n",
        "plt.savefig(\"elbow_method.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define K-Means Clustering Model\n",
        "num_clusters = 10\n",
        "K_Means = KMeans(n_clusters=num_clusters,random_state=0)\n",
        "K_Means.fit(X_pos_clustering) # Fit the K means clustering algorithm to only the positive data\n",
        "\n",
        "# Display the X values of the centroids\n",
        "print(\"These are the centroids in the original normalized data: \\n\")\n",
        "centroids = K_Means.cluster_centers_*X_div # These are the centroids in the original data\n",
        "centroids = pd.DataFrame(centroids, columns=df.columns[:-1], index=list(range(1,num_clusters+1)))\n",
        "display(centroids.T)"
      ],
      "metadata": {
        "id": "M53gQr0DRVMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_assignments = [[int(K_Means.predict(X_pos_clustering[i].reshape(1,-1))), X_pos_lime[i]] for i in range(len(X_pos_clustering))]"
      ],
      "metadata": {
        "id": "DIS4Ei9LSvAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clusters_dict = {\"Cluster \" + str(i): np.array([j[1] for j in cluster_assignments if j[0] == i]) for i in range(num_clusters)}"
      ],
      "metadata": {
        "id": "Bz4dEE_0RzTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nn_predict(data):\n",
        "  pred = model_nn.predict(data).reshape(-1)\n",
        "  probs = np.array(list(zip(1-pred, pred)))\n",
        "  return probs"
      ],
      "metadata": {
        "id": "BmFFamVtJuwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_t,\n",
        "    feature_names=df.columns[:-1],\n",
        "    class_names=['no', 'yes'],\n",
        "    mode='classification')"
      ],
      "metadata": {
        "id": "0ctM6wXldIdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = list(df.columns[:-1])\n",
        "impact = {}\n",
        "\n",
        "for ii in range(num_clusters):\n",
        "  impact[\"Cluster \" + str(ii)] = {col: [] for col in cols}\n",
        "\n",
        "  for i in range(clusters_dict[\"Cluster \" + str(ii)].shape[0]):\n",
        "    exp = explainer.explain_instance(\n",
        "      data_row=clusters_dict[\"Cluster \" + str(ii)][i], \n",
        "      predict_fn=nn_predict, num_features=18)\n",
        "    features = exp.as_map()\n",
        "    \n",
        "    for j in list(features.values())[0]:\n",
        "      impact[\"Cluster \" + str(ii)][cols[j[0]]].append(j[1])"
      ],
      "metadata": {
        "id": "e1HYICQVE8Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(impact, open(\"impact.dat\", \"wb\"))"
      ],
      "metadata": {
        "id": "U680izl9G9fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "impact = pickle.load(open(\"/content/impact.dat\", \"rb\"))"
      ],
      "metadata": {
        "id": "OIrRQbTjiRZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling_distribution(data, sample_size):\n",
        "  np.random.seed(0)\n",
        "  np.random.shuffle(data)\n",
        "  means = []\n",
        "  for i in range(int(len(data) / sample_size - 1)):\n",
        "    means.append(np.mean(data[sample_size*i:sample_size*(i+1)]))\n",
        "  means.append(np.mean(data[sample_size*(i+1):]))\n",
        "  return np.array(means)"
      ],
      "metadata": {
        "id": "54PqxGFv_531"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(20,40))\n",
        "\n",
        "nbins = 10\n",
        "colors = ['r', 'g', 'b', 'y', 'c', 'm', 'k', 'tab:brown', 'tab:orange', 'tab:gray']\n",
        "num_clusters = 10\n",
        "counter = 1\n",
        "bimodal = [\"Age\", \"RestingBP\", \"Cholesterol\", \"MaxHR\", \"Oldpeak\"]\n",
        "n = 4\n",
        "x_labels = [\n",
        "            [0,1,2,3,4,5,6],\n",
        "            [-60,-40,-20,0,20,-40],\n",
        "            [0.5,1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5],\n",
        "            [0,1,2,3,4,5,6,7],\n",
        "            [19,19.5,20.0,20.5,21.0,21.5,22.0],\n",
        "            [0,2,4,6,8,10],\n",
        "            [6.5,7,7.5,8,8.5,9,9.5,10],\n",
        "            [0,2,4,6,8,10,12,14],\n",
        "            [6,6.5,7,7.5,8,8.5,9,9.5,10],\n",
        "            [16,17,18,19,20,21],\n",
        "            [11.5,12,12.5,13,13.5,14,14.5,15,15.5],\n",
        "            [6,7,8,9,10,11,12],\n",
        "            [1,2,3,4,5,6],\n",
        "            [-0.5,0,0.5,1,1.5,2],\n",
        "            [2,2.5,3,3.5,4,4.5,5,5.5,6],\n",
        "            [4,5,6,7,8,9,10],\n",
        "            [15.5,16,16.5,17,17.5,18,18.5,19,19.5],\n",
        "            [7.5,8,8.5,9,9.5,10,10.5]\n",
        "]\n",
        "for i in list(df.columns[:-1]):\n",
        "  ax = fig.add_subplot(6, 3, counter, projection='3d')\n",
        "  max_range_x = 0\n",
        "  xs_track = np.array(())\n",
        "  for j in range(num_clusters):\n",
        "    if i in bimodal:\n",
        "      subdict = impact[\"Cluster \" + str(j)]\n",
        "      distribution = sampling_distribution(np.abs(subdict[i]), sample_size=n)\n",
        "      hist, bins = np.histogram(distribution, bins=10)\n",
        "    else:  \n",
        "      subdict = impact[\"Cluster \" + str(j)]\n",
        "      ys = np.abs(subdict[i])\n",
        "      # ys = np.random.normal(loc=locs[j], scale=10, size=2000)\n",
        "      hist, bins = np.histogram(ys, bins=nbins)\n",
        "    hist = hist/np.sum(hist)\n",
        "    xs = (bins[:-1] + bins[1:])/2\n",
        "    xs = xs * 1000 # otherwise plotting won't work \n",
        "    range_x = np.abs(np.max(xs) - np.min(xs))\n",
        "    if range_x > max_range_x:\n",
        "      max_range_x = range_x\n",
        "      xs_track = xs\n",
        "    ax.bar(xs, hist, zs=j, zdir='y', color=colors[j], ec=colors[j], alpha=0.8, label=\"Cluster \" + str(j))\n",
        "  # print(xs_track.min(), xs_track.max())\n",
        "  if i == \"RestingBP\":\n",
        "    ax.legend(bbox_to_anchor=(1.3,0.8))\n",
        "  ax.set_xlabel('Probability')\n",
        "  # ax.set_xticklabels([round(i,3) for i in (xs_track/1000)]) # adjusting tick labels back  \n",
        "  ax.set_yticks(np.arange(10))\n",
        "  ax.set_ylabel('Cluster No.')\n",
        "  ax.set_zlabel('Frequency')\n",
        "  ax.set_title(\"Impact of \" + str(i) + \" Across Clusters\", pad=20)\n",
        "  ax.set_xticklabels([str(k) for k in x_labels[counter-1]])\n",
        "  # labels = [str(np.array(item.get_text()).astype(float)/10) for item in ax.get_xticklabels()]\n",
        "  # ax.set_xticklabels(labels)\n",
        "  \n",
        "  counter += 1\n",
        "plt.subplots_adjust(wspace=0, hspace=0.05)\n",
        "plt.savefig(\"impact_all_clusters_3D.pdf\", bbox_inches='tight')\n",
        "plt.show()\n",
        "  "
      ],
      "metadata": {
        "id": "40OgD8O9fDib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_clusters):\n",
        "  print(len(impact[\"Cluster \" + str(i)][\"Age\"]))"
      ],
      "metadata": {
        "id": "yBrmX-RtzKH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(6,3,figsize=(15,20))\n",
        "coords = [(i,j) for i in range(6) for j in range(3)]\n",
        "counter = 0 \n",
        "bimodal = [\"Age\", \"RestingBP\", \"Cholesterol\", \"MaxHR\", \"Oldpeak\"]\n",
        "n = 4\n",
        "num_clusters = 10\n",
        "\n",
        "for i in list(df.columns[:-1]):\n",
        "  for j in range(num_clusters):\n",
        "    if i in bimodal:\n",
        "      subdict = impact[\"Cluster \" + str(j)]\n",
        "      distribution = sampling_distribution(np.abs(subdict[i]), sample_size=n)\n",
        "      hist, bins = np.histogram(distribution, bins=10)\n",
        "      hist = hist/np.sum(hist)\n",
        "      xs = (bins[:-1] + bins[1:])/2\n",
        "      xs = xs * 100\n",
        "      ax[coords[counter]].bar(xs, hist, label=\"Cluster \" + str(j))\n",
        "    else:\n",
        "      subdict = impact[\"Cluster \" + str(j)]\n",
        "      hist, bins = np.histogram(np.abs(subdict[i]), bins=10)\n",
        "      hist = hist/np.sum(hist)\n",
        "      xs = (bins[:-1] + bins[1:])/2\n",
        "      xs = xs * 100\n",
        "      ax[coords[counter]].bar(xs, hist, label=\"Cluster \" + str(j))\n",
        "  if i == \"RestingBP\":\n",
        "    ax[coords[counter]].legend(bbox_to_anchor=(1.2,1))\n",
        "  ax[coords[counter]].set_title(\"Impact of \" + str(i) + \" Across Clusters\")\n",
        "  ax[coords[counter]].set_xlabel(\"Probability\")\n",
        "  ax[coords[counter]].set_ylabel(\"Frequency\")\n",
        "  counter += 1\n",
        "plt.subplots_adjust(hspace=0.4)\n",
        "plt.savefig(\"impact_all_clusters_2D_absolutevalue.pdf\", bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wVktCLnoidJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(5,2,figsize=(13,20))\n",
        "coords = [(i,j) for i in range(5) for j in range(2)]\n",
        "counter = 0\n",
        "colors = ['b','tab:orange','g','k','tab:purple','tab:pink','tab:brown','tab:gray','y','r',\n",
        "          'c','m','lime','navy','yellow','peru','mistyrose','skyblue']\n",
        "\n",
        "for j in range(num_clusters):\n",
        "  subdict = impact[\"Cluster \" + str(j)]\n",
        "  for i in list(df.columns[:1]) + list(df.columns[2:-1]):\n",
        "    hist, bins = np.histogram(np.abs(subdict[i]), bins=10)\n",
        "    hist = hist/np.sum(hist)\n",
        "    xs = (bins[:-1] + bins[1:])/2\n",
        "    xs = xs*100\n",
        "    ax[coords[counter]].bar(xs, hist, label=i, color=colors[list(df.columns).index(i)], alpha=1)\n",
        "  if j == 1:\n",
        "    ax[coords[counter]].legend(bbox_to_anchor=(1.1,1))\n",
        "  ax[coords[counter]].set_title(\"Impact of Features on Cluster \" + str(j))\n",
        "  ax[coords[counter]].set_xlabel(\"Probability\")\n",
        "  ax[coords[counter]].set_ylabel(\"Frequency\")\n",
        "  counter += 1\n",
        "plt.subplots_adjust(hspace=0.4)\n",
        "plt.savefig(\"impact_all_features_2D_excludingage_absolutevalue.pdf\", bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LsL5YLdBllwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_scores = np.zeros((num_clusters, len(df.columns[:-1])))\n",
        "p_vals = np.zeros((num_clusters, len(df.columns[:-1])))\n",
        "degs_freedom = np.zeros((num_clusters, len(df.columns[:-1])))\n",
        "bimodal = [\"Age\", \"RestingBP\", \"Cholesterol\", \"MaxHR\", \"Oldpeak\"]\n",
        "n = 4\n",
        "num_clusters = 10\n",
        "\n",
        "for i in range(num_clusters):  \n",
        "  for j in range(len(df.columns[:-1])):\n",
        "    if str(df.columns[j]) in bimodal:\n",
        "      subdict = impact[\"Cluster \" + str(i)][str(df.columns[j])]\n",
        "      distribution = sampling_distribution(np.abs(subdict), sample_size=n)\n",
        "      mean = np.mean(distribution)\n",
        "      std = np.std(distribution) * (n ** 0.5)\n",
        "      t_score = mean / (std / (len(distribution) ** 0.5))\n",
        "      deg_freedom = len(distribution) - 1\n",
        "    else: \n",
        "      mean = np.mean(impact[\"Cluster \" + str(i)][str(df.columns[j])])\n",
        "      std = np.std(impact[\"Cluster \" + str(i)][str(df.columns[j])])\n",
        "      t_score = mean / (std / (len(impact[\"Cluster \" + str(i)][str(df.columns[j])]) ** 0.5))\n",
        "      deg_freedom = len(list(impact[\"Cluster \" + str(i)].values())[0]) - 1\n",
        "    p = t.cdf(min(t_score, -t_score), df=deg_freedom)\n",
        "    t_scores[i][j] = t_score\n",
        "    p_vals[i][j] = p\n",
        "    degs_freedom[i][j] = deg_freedom\n",
        "\n",
        "# t_scores[:,1] and p_vals[:,1] will be NaN because the impact of the \"Sex\" feature is 0"
      ],
      "metadata": {
        "id": "KM7T7bIhrTL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(p_vals.T)"
      ],
      "metadata": {
        "id": "QIBlw38fP0KE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}